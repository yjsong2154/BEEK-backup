{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "온도 습도 등등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_weather(loc_code, page):\n",
    "    param = {\n",
    "        'ServiceKey' : 'dLeJY56I9i5QWd6UksGvqxOsIKaVQ3Aa9rNJZW3rOlPd6FBEoTlhtmmjMsghEicTUqb64WaPkNqv852BGEBLIA=='\n",
    "        , 'pageNo' : page\n",
    "        , 'numOfRows' : '100'\n",
    "        , 'dataType' : 'XML'\n",
    "        , 'dataCd' : 'ASOS'\n",
    "        , 'dateCd' : 'DAY'\n",
    "        , 'startDt' : '20140101'\n",
    "        , 'endDt' : '20181231'\n",
    "        , 'stnIds' : str(loc_code)\n",
    "    }\n",
    "    p_param = parse.urlencode(param) # 파라미터 인코딩\n",
    "\n",
    "    url = 'http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList'\n",
    "\n",
    "    request_info = requests.get(url + '?' + p_param)\n",
    "    soup = BeautifulSoup(request_info.text, 'html.parser')\n",
    "    \n",
    "#     print(soup.prettify())\n",
    "#     print('page :', page ,'complete')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing_bs(raw_bs):\n",
    "    items = raw_bs.select('item')\n",
    "    return_arr = []\n",
    "    \n",
    "    arr_code = [\n",
    "        'stnnm' , 'tm' , 'avgTa' , 'maxTa', 'minTa' , 'sumRn' , 'avgWs' , 'avgRhm'\n",
    "    ]\n",
    "    \n",
    "    for item in items:\n",
    "        temp_arr = []\n",
    "        for key in arr_code:\n",
    "            sel_data = item.select_one(key).string\n",
    "            if sel_data is not None:\n",
    "                temp_arr.append(sel_data)\n",
    "            else:\n",
    "                temp_arr.append(None)\n",
    "        return_arr.append(temp_arr)\n",
    "        \n",
    "    return return_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc : 90 complete\n",
      "loc : 93 complete\n",
      "loc : 95 complete\n",
      "loc : 98 complete\n",
      "loc : 99 complete\n",
      "loc : 100 complete\n",
      "loc : 101 complete\n",
      "loc : 102 complete\n",
      "loc : 104 complete\n",
      "loc : 105 complete\n",
      "loc : 106 complete\n",
      "loc : 108 complete\n",
      "loc : 112 complete\n",
      "loc : 114 complete\n",
      "loc : 115 complete\n",
      "loc : 119 complete\n",
      "loc : 121 complete\n",
      "loc : 127 complete\n",
      "loc : 129 complete\n",
      "loc : 130 complete\n",
      "loc : 131 complete\n",
      "loc : 133 complete\n",
      "loc : 135 complete\n",
      "loc : 136 complete\n",
      "loc : 212 complete\n",
      "loc : 126 complete\n",
      "loc : 127 complete\n",
      "loc : 221 complete\n",
      "loc : 226 complete\n",
      "loc : 232 complete\n",
      "loc : 235 complete\n",
      "loc : 236 complete\n",
      "loc : 238 complete\n",
      "loc : 239 complete\n",
      "loc : 243 complete\n",
      "loc : 244 complete\n",
      "loc : 245 complete\n",
      "loc : 247 complete\n",
      "loc : 248 complete\n",
      "loc : 251 complete\n",
      "loc : 252 complete\n",
      "loc : 253 complete\n",
      "loc : 254 complete\n",
      "loc : 255 complete\n",
      "loc : 257 complete\n",
      "loc : 258 complete\n",
      "loc : 259 complete\n",
      "loc : 260 complete\n",
      "loc : 136 complete\n",
      "loc : 137 complete\n",
      "loc : 138 complete\n",
      "loc : 140 complete\n",
      "loc : 143 complete\n",
      "loc : 146 complete\n",
      "loc : 152 complete\n",
      "loc : 155 complete\n",
      "loc : 156 complete\n",
      "loc : 159 complete\n",
      "loc : 162 complete\n",
      "loc : 165 complete\n",
      "loc : 168 complete\n",
      "loc : 169 complete\n",
      "loc : 170 complete\n",
      "loc : 172 complete\n",
      "loc : 174 complete\n",
      "loc : 177 complete\n",
      "loc : 184 complete\n",
      "loc : 185 complete\n",
      "loc : 188 complete\n",
      "loc : 189 complete\n",
      "loc : 192 complete\n",
      "loc : 201 complete\n",
      "loc : 202 complete\n",
      "loc : 203 complete\n",
      "loc : 211 complete\n",
      "loc : 260 complete\n",
      "loc : 261 complete\n",
      "loc : 262 complete\n",
      "loc : 263 complete\n",
      "loc : 264 complete\n",
      "loc : 266 complete\n",
      "loc : 268 complete\n",
      "loc : 271 complete\n",
      "loc : 272 complete\n",
      "loc : 273 complete\n",
      "loc : 276 complete\n",
      "loc : 277 complete\n",
      "loc : 278 complete\n",
      "loc : 279 complete\n",
      "loc : 281 complete\n",
      "loc : 283 complete\n",
      "loc : 284 complete\n",
      "loc : 285 complete\n",
      "loc : 288 complete\n",
      "loc : 289 complete\n",
      "loc : 294 complete\n",
      "loc : 295 complete\n"
     ]
    }
   ],
   "source": [
    "arr_col = [ '위치', '시간', '평균 기온', '최고 기온', '최저 기온', '강수량', '풍속', '습도' ]\n",
    "\n",
    "loc_arr = [90,93,95,98,99,100,101,102,104,105,106,108,112,114,115,119,121,127,129,130,131,133\n",
    "           ,135,136,212,126,127,221,226,232,235,236,238,239,243,244,245,247,248,251,252,253,254,255\n",
    "           ,257,258,259,260,136,137,138,140,143,146,152,155,156,159,162,165,168,169,170,172,174\n",
    "           ,177,184,185,188,189,192,201,202,203,211,260,261,262,263,264,266,268,271,272,273,276,277\n",
    "           ,278,279,281,283,284,285,288,289,294,295]\n",
    "\n",
    "weather_list = []\n",
    "\n",
    "for loc_code in loc_arr:\n",
    "    for i in range(19):\n",
    "        weather_html = crawling_weather(loc_code, i+1)\n",
    "        weather_list.extend(listing_bs(weather_html))\n",
    "    print('loc :', loc_code ,'complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pd = pd.DataFrame(weather_list)\n",
    "weather_pd.columns = arr_col\n",
    "SAVE_POINT = 'C:\\dev_folder\\dip\\TensorFlow\\Data voucher\\Mirint data\\data\\weather\\날씨 일별 정보_2014~2018.csv'\n",
    "weather_pd.to_csv(SAVE_POINT, sep=',', na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
